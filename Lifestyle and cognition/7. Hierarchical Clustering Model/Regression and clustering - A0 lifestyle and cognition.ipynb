{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc51ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install researchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import researchpy as rp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "##TO MODIFY BY USER\n",
    "### Instruction: You will need to run thise codeonce for each Assessment number wanted (A0, A1, A2) \n",
    "#### Enter the directory with the cleaned csv file (folder with the file generated by 1_DataCleaner)\n",
    "path = '/Users/malika/Documents/Five Lives/SI Data Analysis/LifestyleCognition/Datasets & Data cleaning/'\n",
    "Data = pd.read_csv(path + 'DataframeCogPerfA0.csv')\n",
    "\n",
    "plot = '/Users/malika/Documents/Five Lives/SI Data Analysis/LifestyleCognition/HierarchicalClusteringAnalysis/A0-RT/Plots - Regression and clustering/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd90e09",
   "metadata": {},
   "source": [
    "Clustering Analyisis\n",
    "Great tutorial: https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.set_index('participant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57149c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestyle = ['A0PA_duration',\n",
    " 'A0PA_intensity',\n",
    " 'A0PA_score',\n",
    " 'A0smoking_situation',\n",
    " 'A0smoking_amount',\n",
    " 'A0socialI',\n",
    " 'A0loneliness',\n",
    " 'A0sleep_problems',\n",
    " 'A0fruit_veg',\n",
    " 'A0alcohol_unit',\n",
    " 'A0glasses_water',\n",
    " 'A0time_reading',\n",
    " 'A0time_mental_stimulation',\n",
    " 'A0time_instrument',\n",
    " 'A0time_skill',\n",
    " 'A0relaxed_scale',\n",
    " 'A0mood_rate',\n",
    " 'A0enjoyment_activities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da913e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cog = ['A0cast_performance',\n",
    "       'A0snap_category_performance', 'A0snap_initials_performance',\n",
    "       'A0swift_incongruent_performance', 'A0swift_congruent_performance',\n",
    "       'A0twist_performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab110604",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3592b41f",
   "metadata": {},
   "source": [
    "## Lifestyle factors predicting cognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fd995",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A0PA_duration predicts A0snap_category_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75402301",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 'A0_age + A0male'\n",
    "for to_predict in cog:\n",
    "    # drop nan in each subset to predict to avoid errors due to too many nan\n",
    "    model_sum = ['by ' + to_predict]\n",
    "    for predictor in lifestyle:\n",
    "        model_sum.append(predictor)\n",
    "        df = Data.dropna(axis = 0, subset = [to_predict, predictor])\n",
    "        try:\n",
    "            #Model\n",
    "            m = to_predict + ' ~ ' + predictor + ' + ' + c\n",
    "            mdf_p = OLS.from_formula(m, df)\n",
    "            mdf = mdf_p.fit()\n",
    "            #Create a list to save the models\n",
    "            model_sum.append(mdf.summary())\n",
    "            file_name = to_predict\n",
    "            path = plot + file_name+'.txt'\n",
    "            fp= open(path, 'w')\n",
    "            with open(path, 'w') as fp:\n",
    "                for item in model_sum:\n",
    "                    # write each item on a new line\n",
    "                    fp.write(\"%s\\n\" % item)\n",
    "                    print('Done')\n",
    "        except:\n",
    "            fail = to_predict + '_by_' + predictor\n",
    "            fail_sum.append(fail)\n",
    "            path = plot + 'ErrorRaised.txt'\n",
    "            fp= open(path, 'w')\n",
    "            with open(path, 'w') as fp:\n",
    "                for item in fail_sum:\n",
    "                    # write each item on a new line\n",
    "                    fp.write(\"%s\\n\" % item)\n",
    "                    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c758d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_var = ['A0PA_duration', 'A0PA_intensity', 'A0PA_score']\n",
    "sleep_var = 'A0sleep_problems'\n",
    "diet_var =  ['A0fruit_veg', 'A0alcohol_unit', 'A0glasses_water']\n",
    "\n",
    "smoking_var =  ['A0smoking_situation', 'A0smoking_amount']\n",
    "mood_var =  ['A0relaxed_scale', 'A0mood_rate', 'A0enjoyment_activities']\n",
    "mental_stim_var =  ['A0socialI', 'A0loneliness', 'A0time_mental_stimulation', 'A0time_instrument', 'A0time_skill', 'A0time_reading']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfeacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FL_pillars = [physical_var, sleep_var, diet_var, mood_var, mental_stim_var, smoking_var ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c51929",
   "metadata": {},
   "outputs": [],
   "source": [
    "for predictor in FL_pillars:\n",
    "    for i in range(1, len(predictor)):\n",
    "        m_predictor = predictor[0]\n",
    "        m_predictor = m_predictor + ' + ' + predictor[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88969d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat models but on different pillars\n",
    "\n",
    "smoking =  'A0smoking_situation + A0smoking_amount'\n",
    "FL_pillars = []\n",
    "\n",
    "## Model reproeduced on FL pillars\n",
    "FL_pillars = [physical_var, sleep_var, diet_var, mood_var, mental_stim_var, smoking_var ]\n",
    "fail_sum = []\n",
    "### For list for cognitive change variables\n",
    "for to_predict in cog:\n",
    "    df = Data.dropna(axis = 0, subset = [to_predict])\n",
    "    # drop nan in each subset to predict to avoid errors due to too many nan\n",
    "    model_sum = [to_predict]\n",
    "    for predictor in FL_pillars:\n",
    "        df = Data.dropna(axis = 0, subset = predictor)\n",
    "        try:\n",
    "            #Model\n",
    "            ## Build the model formula based on the listt of predictors\n",
    "            for i in range(1, len(predictor)):\n",
    "                m_predictor = predictor[0]\n",
    "                m_predictor = m_predictor + ' + ' + predictor[i]\n",
    "            \n",
    "            m = to_predict + ' ~ ' + m_predictor + ' + ' + c\n",
    "            mdf_p = OLS.from_formula(m, df)\n",
    "            mdf = mdf_p.fit()\n",
    "            #Create a list to save the models\n",
    "            model_sum.append(mdf.summary())\n",
    "            file_name = to_predict\n",
    "            path = plot + 'pillar/'+ file_name+'.txt'\n",
    "            fp= open(path, 'w')\n",
    "            with open(path, 'w') as fp:\n",
    "                for item in model_sum:\n",
    "                    # write each item on a new line\n",
    "                    fp.write(\"%s\\n\" % item)\n",
    "                    print('Done')\n",
    "        except:\n",
    "            fail = to_predict + '_by_' + m_predictor\n",
    "            fail_sum.append(fail)\n",
    "            path = plot + 'pillar/'+ file_name+'.txt'\n",
    "            fp= open(path, 'w')\n",
    "            with open(path, 'w') as fp:\n",
    "                for item in fail_sum:\n",
    "                    # write each item on a new line\n",
    "                    fp.write(\"%s\\n\" % item)\n",
    "                    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef2edb",
   "metadata": {},
   "source": [
    "most significant results are found for snap category\n",
    "among the LS variables significant, the 3 that stood out as most significant are time_reading',\n",
    "time_mental_stimulation',\n",
    "relaxed_scale',\n",
    "\n",
    "Lets explore with those"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3ec17",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering\n",
    "## 2 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ee76a",
   "metadata": {},
   "source": [
    "time_reading & time_mental_stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806daff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Data[['A0time_reading', 'A0time_mental_stimulation' ]].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d56fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.values\n",
    "X= StandardScaler().fit_transform(X) # normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37bf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Using the dendrogram to find the optimal numbers of clusters. \n",
    "# First thing we're going to do is to import scipy library. scipy is #an open source Python library that contains tools to do #hierarchical clustering and building dendrograms. Only import the #needed tool.\n",
    "import scipy.cluster.hierarchy as sch\n",
    "#Lets create a dendrogram variable linkage is actually the algorithm #itself of hierarchical clustering and then in linkage we have to #specify on which data we apply and engage. This is X dataset\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method  = \"ward\"))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Customers')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Fitting hierarchical clustering to the Mall_Customes dataset\n",
    "# There are two algorithms for hierarchical clustering: #Agglomerative Hierarchical Clustering and \n",
    "# Divisive Hierarchical Clustering. We choose Euclidean distance and ward method for our algorithm class\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage ='ward')\n",
    "# Lets try to fit the hierarchical clustering algorithm  to dataset #X while creating the clusters vector that tells for each customer #which cluster the customer belongs to.\n",
    "y_hc=hc.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37236aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ac5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8adcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Visualizing the clusters. This code is similar to k-means #visualization code. We only replace the y_kmeans vector name to #y_hc for the hierarchical clustering\n",
    "plt.scatter(X[y_hc==0, 0], X[y_hc==0, 1], s=100, c='red', label ='Cluster 1')\n",
    "plt.scatter(X[y_hc==1, 0], X[y_hc==1, 1], s=100, c='blue', label ='Cluster 2')\n",
    "plt.scatter(X[y_hc==2, 0], X[y_hc==2, 1], s=100, c='green', label ='Cluster 3')\n",
    "#plt.scatter(X[y_hc==3, 0], X[y_hc==3, 1], s=100, c='cyan', label ='Cluster 4')\n",
    "#plt.scatter(X[y_hc==4, 0], X[y_hc==4, 1], s=100, c='magenta', label ='Cluster 5')\n",
    "plt.title('Clusters of Participants (Hierarchical Clustering Model)')\n",
    "plt.xlabel('A0time_reading')\n",
    "plt.ylabel('A0time_mental_stimulation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cae7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_label'] = y_hc\n",
    "dfa = df.join(Data['A0snap_category_performance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfa.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28440c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(dfa['A0snap_category_performance'].groupby(dfa['cluster_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = dfa.columns[0] + ' & ' + dfa.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad126fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00268fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = dfa.columns[0] + ' & ' + dfa.columns[1]\n",
    "x ='A0snap_category_performance'\n",
    "    #define mean and median\n",
    "median = dfa[x].median()\n",
    "mean = \"%.2f\" % dfa[x].mean() \n",
    "    #plot figures\n",
    "plt.figure(figsize=(3, 5))\n",
    "sns.displot(data = dfa, x = x, hue = 'cluster_label')\n",
    "plt.axvline(dfa[x].median(), linestyle='dotted', color = 'magenta', label = f'median= {median}')\n",
    "plt.axvline(dfa[x].mean(), linestyle='dotted', color = 'blue', label = f'mean= {mean}')\n",
    "\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title(title + ':A0snap_category_performance by group cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe18190",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 5))\n",
    "sns.boxplot(data = dfa, x = 'cluster_label', y = 'A0snap_category_performance', color = 'pink')\n",
    "plt.title(title + ':A0snap_category_performance by group cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab47dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = dfa.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8287296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.groupby('cluster_label')['A0snap_category_performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.groupby('cluster_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpe0 = dfb['A0snap_category_performance'][dfb['cluster_label']==0]\n",
    "grpe1 = dfb['A0snap_category_performance'][dfb['cluster_label']==1]\n",
    "grpe2 = dfb['A0snap_category_performance'][dfb['cluster_label']==2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_val, p_val = stats.f_oneway(grpe0, grpe1, grpe2)  \n",
    " \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979bb6b",
   "metadata": {},
   "source": [
    "### time reading and relaxed scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Data[['A0time_reading', 'A0relaxed_scale' ]].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973957cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.values\n",
    "X= StandardScaler().fit_transform(X) # normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86449131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Using the dendrogram to find the optimal numbers of clusters. \n",
    "# First thing we're going to do is to import scipy library. scipy is #an open source Python library that contains tools to do #hierarchical clustering and building dendrograms. Only import the #needed tool.\n",
    "import scipy.cluster.hierarchy as sch\n",
    "#Lets create a dendrogram variable linkage is actually the algorithm #itself of hierarchical clustering and then in linkage we have to #specify on which data we apply and engage. This is X dataset\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method  = \"ward\"))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Customers')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Fitting hierarchical clustering to the Mall_Customes dataset\n",
    "# There are two algorithms for hierarchical clustering: #Agglomerative Hierarchical Clustering and \n",
    "# Divisive Hierarchical Clustering. We choose Euclidean distance and ward method for our algorithm class\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage ='ward')\n",
    "# Lets try to fit the hierarchical clustering algorithm  to dataset #X while creating the clusters vector that tells for each customer #which cluster the customer belongs to.\n",
    "y_hc=hc.fit_predict(X)\n",
    "\n",
    "#5 Visualizing the clusters. This code is similar to k-means #visualization code. We only replace the y_kmeans vector name to #y_hc for the hierarchical clustering\n",
    "plt.scatter(X[y_hc==0, 0], X[y_hc==0, 1], s=100, c='red', label ='Cluster 1')\n",
    "plt.scatter(X[y_hc==1, 0], X[y_hc==1, 1], s=100, c='blue', label ='Cluster 2')\n",
    "plt.scatter(X[y_hc==2, 0], X[y_hc==2, 1], s=100, c='green', label ='Cluster 3')\n",
    "#plt.scatter(X[y_hc==3, 0], X[y_hc==3, 1], s=100, c='cyan', label ='Cluster 4')\n",
    "#plt.scatter(X[y_hc==4, 0], X[y_hc==4, 1], s=100, c='magenta', label ='Cluster 5')\n",
    "plt.title('Clusters of Participants (Hierarchical Clustering Model)')\n",
    "plt.xlabel('A0time_reading')\n",
    "plt.ylabel('A0relaxed_scale')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08174117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_label'] = y_hc\n",
    "dfa = df.join(Data['A0snap_category_performance'])\n",
    "dfa = dfa.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = dfa.columns[0] + ' & ' + dfa.columns[1]\n",
    "\n",
    "x ='A0snap_category_performance'\n",
    "    #define mean and median\n",
    "median = dfa[x].median()\n",
    "mean = \"%.2f\" % dfa[x].mean() \n",
    "    #plot figures\n",
    "plt.figure(figsize=(3, 5))\n",
    "sns.displot(data = dfa, x = x, hue = 'cluster_label')\n",
    "plt.axvline(dfa[x].median(), linestyle='dotted', color = 'magenta', label = f'median= {median}')\n",
    "plt.axvline(dfa[x].mean(), linestyle='dotted', color = 'blue', label = f'mean= {mean}')\n",
    "\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title(title + ': A0snap_category_performance by group cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 5))\n",
    "sns.boxplot(data = dfa, x = 'cluster_label', y = 'A0snap_category_performance', color = 'pink')\n",
    "plt.title('Time reading & Relaxed scale:A0snap_category_performance by group cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcfc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rp.summary_cont(dfa['cluster_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(dfa['A0snap_category_performance'].groupby(dfa['cluster_label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpe0 = dfa['A0snap_category_performance'][dfa['cluster_label']==0]\n",
    "grpe1 = dfa['A0snap_category_performance'][dfa['cluster_label']==1]\n",
    "grpe2 = dfa['A0snap_category_performance'][dfa['cluster_label']==2]\n",
    "\n",
    "f_val, p_val = stats.f_oneway(grpe0, grpe1, grpe2)  \n",
    " \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952474cb",
   "metadata": {},
   "source": [
    "### time mental stim and relaxed scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d48f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Data[['A0time_mental_stimulation', 'A0relaxed_scale' ]].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df.values\n",
    "X= StandardScaler().fit_transform(X) # normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Using the dendrogram to find the optimal numbers of clusters. \n",
    "# First thing we're going to do is to import scipy library. scipy is #an open source Python library that contains tools to do #hierarchical clustering and building dendrograms. Only import the #needed tool.\n",
    "import scipy.cluster.hierarchy as sch\n",
    "#Lets create a dendrogram variable linkage is actually the algorithm #itself of hierarchical clustering and then in linkage we have to #specify on which data we apply and engage. This is X dataset\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method  = \"ward\"))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Customers')\n",
    "plt.ylabel('Euclidean distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfee135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Fitting hierarchical clustering to the Mall_Customes dataset\n",
    "# There are two algorithms for hierarchical clustering: #Agglomerative Hierarchical Clustering and \n",
    "# Divisive Hierarchical Clustering. We choose Euclidean distance and ward method for our algorithm class\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage ='ward')\n",
    "# Lets try to fit the hierarchical clustering algorithm  to dataset #X while creating the clusters vector that tells for each customer #which cluster the customer belongs to.\n",
    "y_hc=hc.fit_predict(X)\n",
    "\n",
    "#5 Visualizing the clusters. This code is similar to k-means #visualization code. We only replace the y_kmeans vector name to #y_hc for the hierarchical clustering\n",
    "plt.scatter(X[y_hc==0, 0], X[y_hc==0, 1], s=100, c='red', label ='Cluster 1')\n",
    "plt.scatter(X[y_hc==1, 0], X[y_hc==1, 1], s=100, c='blue', label ='Cluster 2')\n",
    "plt.scatter(X[y_hc==2, 0], X[y_hc==2, 1], s=100, c='green', label ='Cluster 3')\n",
    "#plt.scatter(X[y_hc==3, 0], X[y_hc==3, 1], s=100, c='cyan', label ='Cluster 4')\n",
    "#plt.scatter(X[y_hc==4, 0], X[y_hc==4, 1], s=100, c='magenta', label ='Cluster 5')\n",
    "plt.title('Clusters of Participants (Hierarchical Clustering Model)')\n",
    "plt.xlabel('A0time_mental_stimulation')\n",
    "plt.ylabel('A0relaxed_scale')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33eb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_label'] = y_hc\n",
    "dfa = df.join(Data['A0snap_category_performance'])\n",
    "dfa = dfa.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ffa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d297edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = dfa.columns[0] + ' & ' + dfa.columns[1]\n",
    "\n",
    "x ='A0snap_category_performance'\n",
    "    #define mean and median\n",
    "median = dfa[x].median()\n",
    "mean = \"%.2f\" % dfa[x].mean() \n",
    "    #plot figures\n",
    "plt.figure(figsize=(3, 5))\n",
    "sns.displot(data = dfa, x = x, hue = 'cluster_label')\n",
    "plt.axvline(dfa[x].median(), linestyle='dotted', color = 'magenta', label = f'median= {median}')\n",
    "plt.axvline(dfa[x].mean(), linestyle='dotted', color = 'blue', label = f'mean= {mean}')\n",
    "\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title(title + ': A0snap_category_performance by group cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c33dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 5))\n",
    "sns.boxplot(data = dfa, x = 'cluster_label', y = 'A0snap_category_performance', color = 'pink')\n",
    "plt.title(title + ': A0snap_category_performance by group cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b61f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(dfa['A0snap_category_performance'].groupby(dfa['cluster_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpe0 = dfa['A0snap_category_performance'][dfa['cluster_label']==0]\n",
    "grpe1 = dfa['A0snap_category_performance'][dfa['cluster_label']==1]\n",
    "grpe2 = dfa['A0snap_category_performance'][dfa['cluster_label']==2]\n",
    "\n",
    "f_val, p_val = stats.f_oneway(grpe0, grpe1, grpe2)  \n",
    " \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.multicomp.pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73008a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey test\n",
    "tukey = pairwise_tukeyhsd(endog=dfa['A0snap_category_performance'],\n",
    "                          groups=dfa['cluster_label'],\n",
    "                          alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efef8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = dfa[dfa['cluster_label']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d6809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = df_diff.columns[0] + ' & ' + dfa.columns[1]\n",
    "\n",
    "x ='A0snap_category_performance'\n",
    "    #define mean and median\n",
    "median = df_diff[x].median()\n",
    "mean = \"%.2f\" % dfa[x].mean() \n",
    "    #plot figures\n",
    "plt.figure(figsize=(3, 5))\n",
    "sns.displot(data = df_diff, x = x, hue = 'cluster_label', palette = ['grey', 'yellow'])\n",
    "plt.axvline(df_diff[x].median(), linestyle='dotted', color = 'magenta', label = f'median= {median}')\n",
    "plt.axvline(df_diff[x].mean(), linestyle='dotted', color = 'blue', label = f'mean= {mean}')\n",
    "\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title(title + ': A0snap_category_performance by group cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f0d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
